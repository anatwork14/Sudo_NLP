# ğŸ“ Text Generation with LSTM

This project implements a **Text Generation Model** using **Deep Learning (LSTM)**.  
It supports Vietnamese text processing with [`underthesea`](https://github.com/undertheseanlp/underthesea) and trains an LSTM-based model to generate new sequences of text.

---

## âš™ï¸ Requirements

- **Python 3.10.x** (required for `underthesea` compatibility)
- PyTorch
- Other dependencies listed in `requirements.txt`

---

## ğŸš€ Setup & Installation

Clone the project and create a virtual environment with Python **3.10**:

```bash
# Create venv with Python 3.10
py -3.10 -m venv venv

# Activate environment
source venv/bin/activate     # Linux / macOS
venv\Scripts\activate        # Windows (PowerShell)

# Install dependencies
pip install -r requirements.txt
bash```

````

---

## ğŸ“‚ Data Source

SOURCE:

1. Download the dataset (provided as a `.zip`) .
2. Unzip it into the `/data` folder.

```
project-root/
â”‚â”€â”€ data/
â”‚   â”œâ”€â”€ your_text_files.txt
â”‚   â”œâ”€â”€ ...
â”‚â”€â”€ main.py
â”‚â”€â”€ model.py
â”‚â”€â”€ train.py
â”‚â”€â”€ predict.py
```

---

## ğŸ§  Training & Usage

- When you run the project, it will check for an existing model file:
  `textgen_model.pth`

- If the file does **not** exist, the script will **train a new model** automatically using:

```python
Trainer.train()
```

- After training, the model is saved as `textgen_model.pth` for future use.

---

## âš¡ Notes on Performance

Generated results may sometimes be **incoherent or meaningless**. This can happen because:

1. **Insufficient training data** â€“
   Currently, the number of documents is limited (`num_doc` in `config.py`, default: `10`).

2. **Data diversity** â€“
   The dataset combines multiple documents from `/data`.
   Each document may have a different **writing style** and **vocabulary usage**, leading to mixed results during training.

---

## ğŸ“Œ Example

Run the main script:

```bash
python main.py
```

Input a seed text when prompted:

```
Enter the text for next generation: mÃ¹a xuÃ¢n
```

Example output:

```
âœ¨ Generated: mÃ¹a xuÃ¢n Ä‘áº¹p vÃ  Ä‘áº§y sá»©c sá»‘ng ...
```

---

## ğŸ› ï¸ Project Structure

```
â”œâ”€â”€ config.py         # Configuration (e.g., num_doc, hyperparameters)
â”œâ”€â”€ dataset.py        # Dataset preprocessing
â”œâ”€â”€ loader.py         # Data loader
â”œâ”€â”€ main.py           # Entry point
â”œâ”€â”€ model.py          # LSTM model definition
â”œâ”€â”€ predict.py        # Text generation logic
â”œâ”€â”€ train.py          # Training script
â”œâ”€â”€ utils.py          # Helper functions
â””â”€â”€ data/             # Dataset (unzipped here)
```

---

## ğŸ“– Summary

- âœ… LSTM-based text generation model
- âœ… Pretrained embeddings with `underthesea` tokenizer
- âœ… Auto-trains if no saved model is found
- âš ï¸ Quality depends heavily on dataset size & consistency
