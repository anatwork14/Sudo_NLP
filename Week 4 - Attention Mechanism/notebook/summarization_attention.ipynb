{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51743c48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:09:18.989198Z",
     "iopub.status.busy": "2025-09-22T16:09:18.988985Z",
     "iopub.status.idle": "2025-09-22T16:09:37.124098Z",
     "shell.execute_reply": "2025-09-22T16:09:37.123153Z"
    },
    "papermill": {
     "duration": 18.141973,
     "end_time": "2025-09-22T16:09:37.125923",
     "exception": false,
     "start_time": "2025-09-22T16:09:18.983950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'vietnews'...\r\n",
      "remote: Enumerating objects: 143827, done.\u001b[K\r\n",
      "remote: Total 143827 (delta 0), reused 0 (delta 0), pack-reused 143827 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (143827/143827), 194.68 MiB | 25.45 MiB/s, done.\r\n",
      "Resolving deltas: 100% (11/11), done.\r\n",
      "Updating files: 100% (150704/150704), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ThanhChinhBK/vietnews.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f91c5d8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:09:37.149607Z",
     "iopub.status.busy": "2025-09-22T16:09:37.149322Z",
     "iopub.status.idle": "2025-09-22T16:09:37.152909Z",
     "shell.execute_reply": "2025-09-22T16:09:37.152365Z"
    },
    "papermill": {
     "duration": 0.01612,
     "end_time": "2025-09-22T16:09:37.153955",
     "exception": false,
     "start_time": "2025-09-22T16:09:37.137835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "572557c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:09:37.177072Z",
     "iopub.status.busy": "2025-09-22T16:09:37.176668Z",
     "iopub.status.idle": "2025-09-22T16:09:37.180112Z",
     "shell.execute_reply": "2025-09-22T16:09:37.179441Z"
    },
    "papermill": {
     "duration": 0.016442,
     "end_time": "2025-09-22T16:09:37.181155",
     "exception": false,
     "start_time": "2025-09-22T16:09:37.164713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "titles = []\n",
    "abstracts = []\n",
    "articles = []\n",
    "source = '/kaggle/working/vietnews/data/train_tokenized'\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "960e0fed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:09:37.202822Z",
     "iopub.status.busy": "2025-09-22T16:09:37.202628Z",
     "iopub.status.idle": "2025-09-22T16:09:57.981949Z",
     "shell.execute_reply": "2025-09-22T16:09:57.981104Z"
    },
    "papermill": {
     "duration": 20.791836,
     "end_time": "2025-09-22T16:09:57.983491",
     "exception": false,
     "start_time": "2025-09-22T16:09:37.191655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for filename in os.listdir(source):\n",
    "    if (count == 90000):\n",
    "        break\n",
    "    file_path = os.path.join(source, filename)   # <-- full path\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            article = []\n",
    "            for i, line in enumerate(f, start=1):\n",
    "                text = re.sub(r'[()]', '', line.strip().lower())      # remove all ( )\n",
    "                text = re.sub(r'[.?!:;,…]+$', '', text)\n",
    "                if i == 1: \n",
    "                    titles.append(text)\n",
    "                elif (i == 3):\n",
    "                    abstracts.append(text)\n",
    "                article.append(text)\n",
    "            articles.append(' '.join(article))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5d0df14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:09:58.005985Z",
     "iopub.status.busy": "2025-09-22T16:09:58.005747Z",
     "iopub.status.idle": "2025-09-22T16:10:37.708079Z",
     "shell.execute_reply": "2025-09-22T16:10:37.707444Z"
    },
    "papermill": {
     "duration": 39.715083,
     "end_time": "2025-09-22T16:10:37.709590",
     "exception": false,
     "start_time": "2025-09-22T16:09:57.994507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "import re\n",
    "\n",
    "def split_sentences(text):\n",
    "    # Very simple splitter: split on ., ! or ? and drop empties\n",
    "    sents = re.sub(r\"[\\[\\]\\(\\)\\'\\\",.!?:]\", \" \", text)\n",
    "    return sents.split()\n",
    "\n",
    "corpus = []\n",
    "\n",
    "# Articles contain many sentences, so break them up first\n",
    "for art in articles:\n",
    "    corpus.append(split_sentences(art))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc3b996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:10:37.732545Z",
     "iopub.status.busy": "2025-09-22T16:10:37.731800Z",
     "iopub.status.idle": "2025-09-22T16:21:07.727232Z",
     "shell.execute_reply": "2025-09-22T16:21:07.726633Z"
    },
    "papermill": {
     "duration": 630.008231,
     "end_time": "2025-09-22T16:21:07.728850",
     "exception": false,
     "start_time": "2025-09-22T16:10:37.720619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# load = Word2Vec.load('word2vec_vi.model')\n",
    "# if not load:\n",
    "#     model = Word2Vec(\n",
    "#         sentences=corpus,\n",
    "#         vector_size=120,   # size of word embeddings\n",
    "#         window=5,          # context window\n",
    "#         min_count=2,       # ignore words that appear only once\n",
    "#         workers=4,         # CPU cores\n",
    "#         sg=1               # 1 = skip-gram; 0 = CBOW\n",
    "#     )\n",
    "\n",
    "#     model.save(\"word2vec_vi.model\")\n",
    "# else:\n",
    "#     model = load\n",
    "# model = Word2Vec(\n",
    "#         sentences=corpus,\n",
    "#         vector_size=120,   # size of word embeddings\n",
    "#         window=5,          # context window\n",
    "#         min_count=2,       # ignore words that appear only once\n",
    "#         workers=4,         # CPU cores\n",
    "#         sg=1               # 1 = skip-gram; 0 = CBOW\n",
    "#     )\n",
    "# model.save(\"word2vec_vi.model\")\n",
    "model = Word2Vec(\n",
    "        sentences=corpus,\n",
    "        vector_size=120,   # size of word embeddings\n",
    "        window=5,          # context window\n",
    "        min_count=2,       # ignore words that appear only once\n",
    "        workers=4,         # CPU cores\n",
    "        sg=1               # 1 = skip-gram; 0 = CBOW\n",
    "    )\n",
    "model.save(\"word2vec_vi.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7a33c7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:07.752120Z",
     "iopub.status.busy": "2025-09-22T16:21:07.751881Z",
     "iopub.status.idle": "2025-09-22T16:21:07.809225Z",
     "shell.execute_reply": "2025-09-22T16:21:07.808143Z"
    },
    "papermill": {
     "duration": 0.070064,
     "end_time": "2025-09-22T16:21:07.810655",
     "exception": false,
     "start_time": "2025-09-22T16:21:07.740591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('csđt', 0.8039906620979309), ('pc45', 0.7666938900947571), ('pc02', 0.7593982219696045), ('pc04', 0.7527320981025696), ('pc46', 0.750519871711731), ('cshs', 0.7472440004348755), ('pc47', 0.746635913848877), ('catp', 0.7228366732597351), ('c47', 0.7191884517669678), ('caq', 0.7135355472564697)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar('công_an', topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e553da61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:07.835300Z",
     "iopub.status.busy": "2025-09-22T16:21:07.834835Z",
     "iopub.status.idle": "2025-09-22T16:21:07.944420Z",
     "shell.execute_reply": "2025-09-22T16:21:07.943471Z"
    },
    "papermill": {
     "duration": 0.122907,
     "end_time": "2025-09-22T16:21:07.945751",
     "exception": false,
     "start_time": "2025-09-22T16:21:07.822844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['và', 'của', 'các', 'trong', 'được', 'có', 'là', 'đã', 'với', 'người']\n"
     ]
    }
   ],
   "source": [
    "top10_freq = sorted(\n",
    "    model.wv.key_to_index.keys(),\n",
    "    key=lambda w: model.wv.get_vecattr(w, \"count\"),\n",
    "    reverse=True\n",
    ")[:10]\n",
    "\n",
    "print(top10_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd492ea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:07.971080Z",
     "iopub.status.busy": "2025-09-22T16:21:07.970849Z",
     "iopub.status.idle": "2025-09-22T16:21:07.974259Z",
     "shell.execute_reply": "2025-09-22T16:21:07.973657Z"
    },
    "papermill": {
     "duration": 0.017335,
     "end_time": "2025-09-22T16:21:07.975431",
     "exception": false,
     "start_time": "2025-09-22T16:21:07.958096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb55ff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:08.000815Z",
     "iopub.status.busy": "2025-09-22T16:21:08.000289Z",
     "iopub.status.idle": "2025-09-22T16:21:08.438551Z",
     "shell.execute_reply": "2025-09-22T16:21:08.437894Z"
    },
    "papermill": {
     "duration": 0.452453,
     "end_time": "2025-09-22T16:21:08.439954",
     "exception": false,
     "start_time": "2025-09-22T16:21:07.987501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "stoi = {w: i+4 for i, w in enumerate(word_vectors.key_to_index)}\n",
    "specials = ['<pad>', '<sos>', '<eos>', '<unk>']\n",
    "for i,s in enumerate(specials): stoi[s] = i\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n",
    "embedding_dim = 120\n",
    "embedding_matrix = np.zeros((len(stoi), embedding_dim))\n",
    "for w, idx in stoi.items():\n",
    "    if w in word_vectors:\n",
    "        embedding_matrix[idx] = word_vectors[w]\n",
    "    else:\n",
    "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e74c9c45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:08.462048Z",
     "iopub.status.busy": "2025-09-22T16:21:08.461849Z",
     "iopub.status.idle": "2025-09-22T16:21:08.467474Z",
     "shell.execute_reply": "2025-09-22T16:21:08.466917Z"
    },
    "papermill": {
     "duration": 0.017745,
     "end_time": "2025-09-22T16:21:08.468527",
     "exception": false,
     "start_time": "2025-09-22T16:21:08.450782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34357445, -0.01881607,  0.44490534, ...,  1.49560657,\n",
       "        -0.10458035, -0.33541327],\n",
       "       [-0.45835551,  1.42854891,  0.28534884, ...,  0.53586882,\n",
       "         0.22003493, -0.15998913],\n",
       "       [ 0.63138211,  0.83444756, -0.33655864, ..., -1.15858037,\n",
       "         0.37780703,  0.48300678],\n",
       "       ...,\n",
       "       [-0.01517487,  0.06603973, -0.10437654, ...,  0.01729302,\n",
       "         0.04389772, -0.23397616],\n",
       "       [-0.03448777,  0.11213791,  0.01215753, ...,  0.0509082 ,\n",
       "         0.12976702, -0.17246613],\n",
       "       [ 0.08124344,  0.10655062, -0.07755142, ...,  0.00344738,\n",
       "         0.15523252, -0.24563707]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd46ad62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:08.490512Z",
     "iopub.status.busy": "2025-09-22T16:21:08.490161Z",
     "iopub.status.idle": "2025-09-22T16:21:13.237272Z",
     "shell.execute_reply": "2025-09-22T16:21:13.236686Z"
    },
    "papermill": {
     "duration": 4.759597,
     "end_time": "2025-09-22T16:21:13.238713",
     "exception": false,
     "start_time": "2025-09-22T16:21:08.479116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class SummDataset(Dataset):\n",
    "    def __init__(self, src_texts, target_texts, vocab, max_src=900, max_tgt=40):\n",
    "        self.src = src_texts\n",
    "        self.tgt = target_texts \n",
    "        self.vocab = vocab\n",
    "        self.max_src = max_src # Max word in an article\n",
    "        self.max_tgt = max_tgt # Max target words\n",
    "\n",
    "    def encode(self, text, max_len):\n",
    "        ids = [self.vocab.get(tok, self.vocab['<unk>']) for tok in text.split()]\n",
    "        ids = ids[:max_len]\n",
    "        return ids + [self.vocab['<pad>']]*(max_len - len(ids))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        src_ids = self.encode(self.src[i], self.max_src)\n",
    "        tgt_ids = [self.vocab['<sos>']] + \\\n",
    "                  self.encode(self.tgt[i], self.max_tgt-2) + \\\n",
    "                  [self.vocab['<eos>']]\n",
    "        tgt_ids = tgt_ids + [self.vocab['<pad>']]*(self.max_tgt - len(tgt_ids))\n",
    "        return torch.LongTensor(src_ids), torch.LongTensor(tgt_ids)\n",
    "\n",
    "    def __len__(self): return len(self.src)\n",
    "\n",
    "train_ds = SummDataset(articles, titles, stoi)\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8b2f0c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:13.309451Z",
     "iopub.status.busy": "2025-09-22T16:21:13.308542Z",
     "iopub.status.idle": "2025-09-22T16:21:13.368315Z",
     "shell.execute_reply": "2025-09-22T16:21:13.367586Z"
    },
    "papermill": {
     "duration": 0.118736,
     "end_time": "2025-09-22T16:21:13.369455",
     "exception": false,
     "start_time": "2025-09-22T16:21:13.250719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92b2c99d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:13.391990Z",
     "iopub.status.busy": "2025-09-22T16:21:13.391768Z",
     "iopub.status.idle": "2025-09-22T16:21:13.396232Z",
     "shell.execute_reply": "2025-09-22T16:21:13.395563Z"
    },
    "papermill": {
     "duration": 0.016743,
     "end_time": "2025-09-22T16:21:13.397322",
     "exception": false,
     "start_time": "2025-09-22T16:21:13.380579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e741c6a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:13.419354Z",
     "iopub.status.busy": "2025-09-22T16:21:13.419139Z",
     "iopub.status.idle": "2025-09-22T16:21:13.422278Z",
     "shell.execute_reply": "2025-09-22T16:21:13.421637Z"
    },
    "papermill": {
     "duration": 0.015246,
     "end_time": "2025-09-22T16:21:13.423289",
     "exception": false,
     "start_time": "2025-09-22T16:21:13.408043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad5b116f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:13.445492Z",
     "iopub.status.busy": "2025-09-22T16:21:13.445270Z",
     "iopub.status.idle": "2025-09-22T16:21:13.451307Z",
     "shell.execute_reply": "2025-09-22T16:21:13.450648Z"
    },
    "papermill": {
     "duration": 0.018325,
     "end_time": "2025-09-22T16:21:13.452320",
     "exception": false,
     "start_time": "2025-09-22T16:21:13.433995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, embedding_weights):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size, padding_idx=stoi['<pad>'])\n",
    "        self.embedding.weight.data.copy_(torch.tensor(embedding_weights))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        # LSTM\n",
    "        self.rnn = nn.LSTM(input_size= embedding_size, hidden_size=hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, hidden_size) # A_foward + A_backward as input and then compress to one\n",
    "        \n",
    "    def forward(self, src):\n",
    "        emb = self.embedding(src)\n",
    "        outputs, (h_n, c_n) = self.rnn(emb)   # outputs: [B,S,2H], h_n/c_n: [2,B,H]\n",
    "\n",
    "        # Ghép 2 hướng lại thành [B, 2H]\n",
    "        h_cat = torch.cat((h_n[-2], h_n[-1]), dim=1)   # [B, 2H]\n",
    "        c_cat = torch.cat((c_n[-2], c_n[-1]), dim=1)   # [B, 2H]\n",
    "\n",
    "        # Chiếu xuống H và thêm chiều num_layers=1\n",
    "        h_final = torch.tanh(self.fc(h_cat)).unsqueeze(0)  # [1,B,H]\n",
    "        c_final = torch.tanh(self.fc(c_cat)).unsqueeze(0)  # [1,B,H]\n",
    "\n",
    "        return self.fc(outputs), (h_final, c_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "720315ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:13.475179Z",
     "iopub.status.busy": "2025-09-22T16:21:13.474644Z",
     "iopub.status.idle": "2025-09-22T16:21:13.479911Z",
     "shell.execute_reply": "2025-09-22T16:21:13.479334Z"
    },
    "papermill": {
     "duration": 0.017833,
     "end_time": "2025-09-22T16:21:13.480951",
     "exception": false,
     "start_time": "2025-09-22T16:21:13.463118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_size*2, hidden_size) # Concat Encoder + Decoder\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        a = encoder_outputs                             # [B, S, H]\n",
    "        h, _ = decoder_hidden               # take only the hidden state\n",
    "        # h shape: [num_layers, B, H]  (here num_layers=1 for decoder)\n",
    "        h = h.permute(1, 0, 2)              # -> [B, 1, H]\n",
    "        B, S, H = encoder_outputs.size()\n",
    "        s = h.repeat(1, S, 1)               # [B, S, H]\n",
    "\n",
    "        energy = torch.relu(self.attn(torch.cat((s, a), dim=2)))  # [B, S, H]\n",
    "        scores = self.v(energy).squeeze(2)              # [B, S]\n",
    "        attn_weights = torch.softmax(scores, dim=1)     # [B, S]\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), a)  # [B, 1, H]\n",
    "        return context, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef450cc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:13.503150Z",
     "iopub.status.busy": "2025-09-22T16:21:13.502974Z",
     "iopub.status.idle": "2025-09-22T16:21:13.507891Z",
     "shell.execute_reply": "2025-09-22T16:21:13.507374Z"
    },
    "papermill": {
     "duration": 0.017226,
     "end_time": "2025-09-22T16:21:13.508920",
     "exception": false,
     "start_time": "2025-09-22T16:21:13.491694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=stoi['<pad>'])\n",
    "        self.rnn = nn.LSTM(hidden_size + emb_size, hidden_size, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_size*2 + emb_size, vocab_size)\n",
    "        self.attention = ModelAttention(hidden_size)\n",
    "\n",
    "    def forward(self, input_token, hidden, encoder_outputs):\n",
    "        # input_token: [B] current word index\n",
    "        emb = self.embedding(input_token).unsqueeze(1)     # [B,1,E]\n",
    "        context, attn_weights = self.attention(hidden, encoder_outputs)\n",
    "        rnn_input = torch.cat((emb, context), dim=2)       # [B,1,E+H]\n",
    "        output, hidden = self.rnn(rnn_input, hidden)       # output: [B,1,H]\n",
    "        concat = torch.cat((output, context, emb), dim=2)  # [B,1,H+H+E]\n",
    "        prediction = self.fc_out(concat).squeeze(1)        # [B,vocab]\n",
    "        return prediction, hidden, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "107a3b8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:13.531672Z",
     "iopub.status.busy": "2025-09-22T16:21:13.531492Z",
     "iopub.status.idle": "2025-09-22T16:21:13.536246Z",
     "shell.execute_reply": "2025-09-22T16:21:13.535747Z"
    },
    "papermill": {
     "duration": 0.017233,
     "end_time": "2025-09-22T16:21:13.537299",
     "exception": false,
     "start_time": "2025-09-22T16:21:13.520066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SummarizationModel(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        input_token = tgt[:,0]        # usually <sos>\n",
    "        outputs = []\n",
    "        for t in range(1, tgt.size(1)):\n",
    "            output, hidden, _ = self.decoder(input_token, hidden, encoder_outputs)\n",
    "            outputs.append(output.unsqueeze(1))\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            input_token = tgt[:,t] if teacher_force else output.argmax(1)\n",
    "        return torch.cat(outputs, dim=1)   # [B, T-1, vocab]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49cd543f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:13.560216Z",
     "iopub.status.busy": "2025-09-22T16:21:13.559833Z",
     "iopub.status.idle": "2025-09-22T16:21:14.996651Z",
     "shell.execute_reply": "2025-09-22T16:21:14.996069Z"
    },
    "papermill": {
     "duration": 1.449613,
     "end_time": "2025-09-22T16:21:14.997961",
     "exception": false,
     "start_time": "2025-09-22T16:21:13.548348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = ModelEncoder(vocab_size=len(stoi), embedding_size=120, hidden_size=256, embedding_weights=embedding_matrix)\n",
    "decoder = ModelDecoder(len(stoi), emb_size=120, hidden_size=256)\n",
    "sum_model   = SummarizationModel(encoder, decoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44a1c8dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:15.022234Z",
     "iopub.status.busy": "2025-09-22T16:21:15.021564Z",
     "iopub.status.idle": "2025-09-22T16:21:18.983075Z",
     "shell.execute_reply": "2025-09-22T16:21:18.982521Z"
    },
    "papermill": {
     "duration": 3.974566,
     "end_time": "2025-09-22T16:21:18.984352",
     "exception": false,
     "start_time": "2025-09-22T16:21:15.009786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=stoi['<pad>'])\n",
    "optimizer = torch.optim.Adam(sum_model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87f21775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:19.008144Z",
     "iopub.status.busy": "2025-09-22T16:21:19.007747Z",
     "iopub.status.idle": "2025-09-22T16:21:19.012801Z",
     "shell.execute_reply": "2025-09-22T16:21:19.012245Z"
    },
    "papermill": {
     "duration": 0.017967,
     "end_time": "2025-09-22T16:21:19.013857",
     "exception": false,
     "start_time": "2025-09-22T16:21:18.995890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, criterion, device, teacher_forcing_ratio=0.5):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for src, tgt in dataloader:           # src: [B,S], tgt: [B,T]\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # model returns predictions for each target step except the first <sos>\n",
    "        output = model(src, tgt, teacher_forcing_ratio)\n",
    "        # output shape: [B, T-1, vocab]\n",
    "\n",
    "        # Align target: skip first token (<sos>)\n",
    "        target = tgt[:, 1:]                # [B, T-1]\n",
    "\n",
    "        # Flatten for CrossEntropy: [(B*(T-1)), vocab]\n",
    "        loss = criterion(\n",
    "            output.reshape(-1, output.size(-1)),\n",
    "            target.reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # optional: gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f715c313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T16:21:19.036697Z",
     "iopub.status.busy": "2025-09-22T16:21:19.036192Z",
     "iopub.status.idle": "2025-09-22T21:20:22.406110Z",
     "shell.execute_reply": "2025-09-22T21:20:22.405306Z"
    },
    "papermill": {
     "duration": 17943.383323,
     "end_time": "2025-09-22T21:20:22.408130",
     "exception": false,
     "start_time": "2025-09-22T16:21:19.024807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: train loss = 2.8282\n",
      "Epoch 02: train loss = 0.4800\n",
      "Epoch 03: train loss = 0.2210\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 15\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_loss = train_one_epoch(sum_model, train_loader,\n",
    "                                 optimizer, criterion, device)\n",
    "    # val_loss = evaluate(model, val_loader, criterion, device)  # if you have val set\n",
    "    if (train_loss <= 0.2):\n",
    "        break\n",
    "    print(f\"Epoch {epoch:02d}: train loss = {train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f48f8a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T21:20:22.433463Z",
     "iopub.status.busy": "2025-09-22T21:20:22.433229Z",
     "iopub.status.idle": "2025-09-22T21:20:23.371456Z",
     "shell.execute_reply": "2025-09-22T21:20:23.370659Z"
    },
    "papermill": {
     "duration": 0.95174,
     "end_time": "2025-09-22T21:20:23.372836",
     "exception": false,
     "start_time": "2025-09-22T21:20:22.421096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(sum_model.state_dict(), \"summarization_model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "247c7908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T21:20:23.397133Z",
     "iopub.status.busy": "2025-09-22T21:20:23.396888Z",
     "iopub.status.idle": "2025-09-22T21:20:23.400754Z",
     "shell.execute_reply": "2025-09-22T21:20:23.400320Z"
    },
    "papermill": {
     "duration": 0.017211,
     "end_time": "2025-09-22T21:20:23.401823",
     "exception": false,
     "start_time": "2025-09-22T21:20:23.384612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_text(text, vocab, max_len=800):\n",
    "    ids = [vocab.get(tok, vocab['<unk>']) for tok in text.split()]\n",
    "    ids = ids[:max_len]\n",
    "    return torch.LongTensor([ids + [vocab['<pad>']] * (max_len - len(ids))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ac483ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T21:20:23.424949Z",
     "iopub.status.busy": "2025-09-22T21:20:23.424768Z",
     "iopub.status.idle": "2025-09-22T21:20:23.429408Z",
     "shell.execute_reply": "2025-09-22T21:20:23.428665Z"
    },
    "papermill": {
     "duration": 0.017598,
     "end_time": "2025-09-22T21:20:23.430597",
     "exception": false,
     "start_time": "2025-09-22T21:20:23.412999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            output = model(src, tgt)  # no teacher forcing\n",
    "            target = tgt[:, 1:]\n",
    "            loss = criterion(output.reshape(-1, output.size(-1)),\n",
    "                             target.reshape(-1))\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4da58eff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T21:20:23.453756Z",
     "iopub.status.busy": "2025-09-22T21:20:23.453540Z",
     "iopub.status.idle": "2025-09-22T21:20:23.458221Z",
     "shell.execute_reply": "2025-09-22T21:20:23.457718Z"
    },
    "papermill": {
     "duration": 0.017359,
     "end_time": "2025-09-22T21:20:23.459150",
     "exception": false,
     "start_time": "2025-09-22T21:20:23.441791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_title_lstm(model, article_text, max_len=40):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # encode_text already returns [1, max_len]\n",
    "        src = encode_text(article_text, stoi).to(device)\n",
    "\n",
    "        encoder_outputs, hidden = model.encoder(src)\n",
    "\n",
    "        input_token = torch.tensor([stoi['<sos>']], device=device)\n",
    "        generated = []\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            output, hidden, _ = model.decoder(input_token, hidden, encoder_outputs)\n",
    "            next_token = output.argmax(1)\n",
    "            if next_token.item() == stoi['<eos>']:\n",
    "                break\n",
    "            generated.append(next_token.item())\n",
    "            input_token = next_token\n",
    "\n",
    "    words = [itos[i] for i in generated]\n",
    "    return \" \".join(words), words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f1e1fef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T21:20:23.482286Z",
     "iopub.status.busy": "2025-09-22T21:20:23.482077Z",
     "iopub.status.idle": "2025-09-22T21:20:23.485950Z",
     "shell.execute_reply": "2025-09-22T21:20:23.485438Z"
    },
    "papermill": {
     "duration": 0.01663,
     "end_time": "2025-09-22T21:20:23.486975",
     "exception": false,
     "start_time": "2025-09-22T21:20:23.470345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_data = '''Bản_án cho đối_tượng giả_danh công_an để lừa_đảo\n",
    "\n",
    "Ngày 25/2 , TAND TP. Đà_Nẵng tuyên_phạt Hồ_Xuân_Huy ( SN 1994 ) , ngụ quận Hải_Châu , 12 năm tù về tội Lừa_đảo chiếm_đoạt tài_sản .\n",
    "\n",
    "Theo lời khai của Huy tại phiên_toà , để có tiền sử_dụng cá_nhân , Huy “ nổ ” là sĩ_quan cục Phòng_chống ma_tuý của bộ Công_an đóng tại TP. Đà_Nẵng , có nguồn mua ô_tô thanh_lý giá rẻ , và khả_năng chạy việc vào ngành công_an .\n",
    "Chỉ với lời “ nổ ” này , từ tháng 10/2016 đến 9/2017 , nhiều người đã bị lừa_đảo với tổng_số tiền 3,2 tỷ đồng .\n",
    "Trong đó , người bị Huy lừa nhiều nhất là vợ_chồng ông Bảo_Th . , ngụ quận Hải_Châu .\n",
    "Huy giới_thiệu với cặp vợ_chồng này mình có suất mua ô_tô thanh_lý giá rẻ và rủ họ mua cùng .\n",
    "Tin lời , vợ_chồng ông Th .\n",
    "đưa cho Huy hơn 1 tỷ đồng .\n",
    "Cùng thủ_đoạn , Huy lừa thêm ông Nguyễn_Tấn_T. 970 triệu đồng , Lê_Quốc_Th .\n",
    "400 triệu đồng , Trần_Nhật_S. 300 triệu đồng …\n",
    "Sau chiêu_thức mua xe thanh_lý , Huy chuyển sang giả_vờ có khả_năng xin việc vào ngành công_an .\n",
    "Với chiêu_thức này , Huy lừa vợ_chồng ông Đinh_Ngọc_H. 250 triệu đồng .\n",
    "Ngoài_ra , Huy hứa_hẹn , tháng 3/2017 sẽ đưa kết_quả cho con ông H. đi làm_việc .\n",
    "Tuy_nhiên , sau nhiều lần hẹn mà không có quyết_định tuyển_dụng , ông H. đã gửi đơn tố_cáo đến cơ_quan Công_an .\n",
    "Từ đó , những hành_vi sai_trái của Huy lần_lượt được truy ra .\n",
    "\n",
    "Huy tại phiên_toà .\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85297e30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T21:20:23.510552Z",
     "iopub.status.busy": "2025-09-22T21:20:23.510325Z",
     "iopub.status.idle": "2025-09-22T21:20:23.581047Z",
     "shell.execute_reply": "2025-09-22T21:20:23.580260Z"
    },
    "papermill": {
     "duration": 0.083684,
     "end_time": "2025-09-22T21:20:23.582280",
     "exception": false,
     "start_time": "2025-09-22T21:20:23.498596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted title: <unk> cho đối_tượng giả_danh công_an để lừa_đảo <unk> 25/2 <unk> <unk> <unk> <unk> tuyên_phạt <unk> <unk> <unk> 1993 <unk> <unk> ngụ quận <unk> <unk> 12 năm tù <unk> tù <unk> tù <unk>\n"
     ]
    }
   ],
   "source": [
    "sample_article = articles[0]  # or any new article string\n",
    "title_pred, words = generate_title_lstm(sum_model, new_data)\n",
    "print(\"Predicted title:\", title_pred)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18671.466677,
   "end_time": "2025-09-22T21:20:26.426119",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-22T16:09:14.959442",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
