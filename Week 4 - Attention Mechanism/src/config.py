# Data source (Need to download from online resource and place it in the format like this)
data_path = 'data/vietnews/data/train_tokenized'
count_max = 90000 # How much articles from training_dataset you want to use
# Pretrain_model (Need to unzip )
word2vec_model_path = 'model/word2vec_vi.model'
summarization_model_path = 'model/summarization_model_weights.pth'

# Word2Vec Config
embedding_size = 120