{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/qhungngo/EVBCorpus.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T07:30:47.904297Z","iopub.execute_input":"2025-09-21T07:30:47.904619Z","iopub.status.idle":"2025-09-21T07:30:49.944532Z","shell.execute_reply.started":"2025-09-21T07:30:47.904597Z","shell.execute_reply":"2025-09-21T07:30:49.943803Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'EVBCorpus'...\nremote: Enumerating objects: 35, done.\u001b[K\nremote: Total 35 (delta 0), reused 0 (delta 0), pack-reused 35 (from 1)\u001b[K\nReceiving objects: 100% (35/35), 35.37 MiB | 38.29 MiB/s, done.\nResolving deltas: 100% (10/10), done.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"english = []\nvietnamese = []\nsource = '/kaggle/working/EVBCorpus/EVBCorpus_EVBNews_v2.0.rar'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:19:51.174305Z","iopub.execute_input":"2025-09-21T08:19:51.174594Z","iopub.status.idle":"2025-09-21T08:19:51.192345Z","shell.execute_reply.started":"2025-09-21T08:19:51.174577Z","shell.execute_reply":"2025-09-21T08:19:51.191554Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"!apt-get install -y unrar     # install unrar utility\n\n# make a folder to extract into\n!mkdir -p /kaggle/working/EVBCorpus_extracted\n\n# extract\n!unrar x /kaggle/working/EVBCorpus/EVBCorpus_EVBNews_v2.0.rar /kaggle/working/EVBCorpus_extracted/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport re\nos.listdir('/kaggle/working/EVBCorpus_extracted')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"source_unzip = '/kaggle/working/EVBCorpus_extracted'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:20:48.469622Z","iopub.execute_input":"2025-09-21T08:20:48.470343Z","iopub.status.idle":"2025-09-21T08:20:48.473533Z","shell.execute_reply.started":"2025-09-21T08:20:48.470321Z","shell.execute_reply":"2025-09-21T08:20:48.472740Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"english, vietnamese = [], []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:20:49.190641Z","iopub.execute_input":"2025-09-21T08:20:49.190883Z","iopub.status.idle":"2025-09-21T08:20:49.194718Z","shell.execute_reply.started":"2025-09-21T08:20:49.190868Z","shell.execute_reply":"2025-09-21T08:20:49.193837Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"en_re = re.compile(r\"<s id='en\\d+'>(.*?)</s>\")\nvn_re = re.compile(r\"<s id='vn\\d+'>(.*?)</s>\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:20:49.693051Z","iopub.execute_input":"2025-09-21T08:20:49.693731Z","iopub.status.idle":"2025-09-21T08:20:49.697388Z","shell.execute_reply.started":"2025-09-21T08:20:49.693710Z","shell.execute_reply":"2025-09-21T08:20:49.696615Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"for filename in os.listdir(source_unzip):\n    file_path = os.path.join(source_unzip, filename)   # <-- full path\n    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n            block_en, block_vn = [], []\n            for line in f:\n                # collect all matches in the current line\n                ens = en_re.findall(line)\n                vns = vn_re.findall(line)\n                if ens: english.append(ens)\n                if vns: vietnamese.append(vns)\n# Pair them up if you want aligned parallel sentences\n    # pairs = list(zip(block_en, block_vn))\n    # english.append(block_en)\n    # vietnamese.append(block_vn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:20:50.398422Z","iopub.execute_input":"2025-09-21T08:20:50.399088Z","iopub.status.idle":"2025-09-21T08:20:50.875068Z","shell.execute_reply.started":"2025-09-21T08:20:50.399065Z","shell.execute_reply":"2025-09-21T08:20:50.874499Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"print(len(english))\nprint(len(vietnamese))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:20:53.109324Z","iopub.execute_input":"2025-09-21T08:20:53.109663Z","iopub.status.idle":"2025-09-21T08:20:53.113764Z","shell.execute_reply.started":"2025-09-21T08:20:53.109642Z","shell.execute_reply":"2025-09-21T08:20:53.112913Z"}},"outputs":[{"name":"stdout","text":"45308\n45308\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"print(english[1000])\nprint(vietnamese[1000])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:20:53.838401Z","iopub.execute_input":"2025-09-21T08:20:53.838759Z","iopub.status.idle":"2025-09-21T08:20:53.842943Z","shell.execute_reply.started":"2025-09-21T08:20:53.838734Z","shell.execute_reply":"2025-09-21T08:20:53.842047Z"}},"outputs":[{"name":"stdout","text":"['Mr Obama , who watched the raid from the White House on monitors , saw his approval rating jump 11 points to 57 % in a New York Times/CBS News poll on Wednesday .']\n['Ông Obama đã xem cuộc đột kích từ màn hình ở Nhà Trắng thấy rằng tỷ lệ ủng hộ ông nhảy lên 11 điểm lên mức 57% trong cuộc thăm dò dư luận trên New York Times / CBS vào hôm thứ Tư .']\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"vietnamese[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:20:56.334322Z","iopub.execute_input":"2025-09-21T08:20:56.334611Z","iopub.status.idle":"2025-09-21T08:20:56.339785Z","shell.execute_reply.started":"2025-09-21T08:20:56.334589Z","shell.execute_reply":"2025-09-21T08:20:56.338942Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"[['Bí mật về các ngôi làng bỏ hoang ở Anh'],\n ['Ký ức mù mờ về hàng ngàn ngôi làng bị lãng quên từ lâu vẫn ám ảnh nước Anh , những nơi cư trú bỗng dưng vắng vẻ và chỉ còn lại đống đổ nát .'],\n ['Khi bắt đầu có một chiến dịch mới để làm sáng tỏ về những câu chuyện bị lãng quên này , thì Magazine mới tự hỏi là - điều gì đã xảy ra và vì sao ?'],\n ['Albert Nash , thợ rèn sống 44 năm ở làng Imber , Wiltshire , được vợ ông là bà Martha thấy là đang ngồi sụp xuống cái đe trong lò rèn của mình .'],\n ['Theo lời bà ấy thì ông đang khóc như một đứa trẻ .']]"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"%pip install underthesea","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from underthesea import word_tokenize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:20:59.024212Z","iopub.execute_input":"2025-09-21T08:20:59.024797Z","iopub.status.idle":"2025-09-21T08:20:59.028286Z","shell.execute_reply.started":"2025-09-21T08:20:59.024770Z","shell.execute_reply":"2025-09-21T08:20:59.027389Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"tokenized = [\n    [word_tokenize(sentence[0].lower(), format=\"text\")]  # keep the same nested structure\n    for sentence in vietnamese\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:21:00.493633Z","iopub.execute_input":"2025-09-21T08:21:00.493904Z","iopub.status.idle":"2025-09-21T08:21:58.565906Z","shell.execute_reply.started":"2025-09-21T08:21:00.493884Z","shell.execute_reply":"2025-09-21T08:21:58.565159Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"tokenized[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:21:58.567578Z","iopub.execute_input":"2025-09-21T08:21:58.567942Z","iopub.status.idle":"2025-09-21T08:21:58.572858Z","shell.execute_reply.started":"2025-09-21T08:21:58.567909Z","shell.execute_reply":"2025-09-21T08:21:58.572033Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"[['bí_mật về các ngôi làng bỏ_hoang ở anh'],\n ['ký_ức mù_mờ về hàng ngàn ngôi làng bị lãng_quên từ lâu vẫn ám_ảnh nước anh , những nơi cư_trú bỗng_dưng vắng_vẻ và chỉ còn lại đống đổ_nát .'],\n ['khi bắt_đầu có một chiến_dịch mới để làm sáng_tỏ về những câu_chuyện bị lãng_quên này , thì magazine mới tự hỏi là - điều gì đã xảy ra và vì sao ?'],\n ['albert nash , thợ_rèn sống 44 năm ở làng imber , wiltshire , được vợ ông là bà martha thấy là đang ngồi sụp xuống cái đe trong lò_rèn của mình .'],\n ['theo lời bà ấy thì ông đang khóc như một đứa trẻ .']]"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"tokenized_vietnamese = []\nfor row in tokenized:\n    sentence = row[0]\n    # remove \", - characters\n    cleaned = re.sub(r'[\"\\-]', '', sentence)\n    # split by space\n    tokens = cleaned.split()\n    tokenized_vietnamese.append(tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:21:58.573685Z","iopub.execute_input":"2025-09-21T08:21:58.573929Z","iopub.status.idle":"2025-09-21T08:21:58.866766Z","shell.execute_reply.started":"2025-09-21T08:21:58.573910Z","shell.execute_reply":"2025-09-21T08:21:58.865868Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"tokenized_vietnamese[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:21:58.868648Z","iopub.execute_input":"2025-09-21T08:21:58.868920Z","iopub.status.idle":"2025-09-21T08:21:58.875443Z","shell.execute_reply.started":"2025-09-21T08:21:58.868903Z","shell.execute_reply":"2025-09-21T08:21:58.874790Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"[['bí_mật', 'về', 'các', 'ngôi', 'làng', 'bỏ_hoang', 'ở', 'anh'],\n ['ký_ức',\n  'mù_mờ',\n  'về',\n  'hàng',\n  'ngàn',\n  'ngôi',\n  'làng',\n  'bị',\n  'lãng_quên',\n  'từ',\n  'lâu',\n  'vẫn',\n  'ám_ảnh',\n  'nước',\n  'anh',\n  ',',\n  'những',\n  'nơi',\n  'cư_trú',\n  'bỗng_dưng',\n  'vắng_vẻ',\n  'và',\n  'chỉ',\n  'còn',\n  'lại',\n  'đống',\n  'đổ_nát',\n  '.'],\n ['khi',\n  'bắt_đầu',\n  'có',\n  'một',\n  'chiến_dịch',\n  'mới',\n  'để',\n  'làm',\n  'sáng_tỏ',\n  'về',\n  'những',\n  'câu_chuyện',\n  'bị',\n  'lãng_quên',\n  'này',\n  ',',\n  'thì',\n  'magazine',\n  'mới',\n  'tự',\n  'hỏi',\n  'là',\n  'điều',\n  'gì',\n  'đã',\n  'xảy',\n  'ra',\n  'và',\n  'vì',\n  'sao',\n  '?'],\n ['albert',\n  'nash',\n  ',',\n  'thợ_rèn',\n  'sống',\n  '44',\n  'năm',\n  'ở',\n  'làng',\n  'imber',\n  ',',\n  'wiltshire',\n  ',',\n  'được',\n  'vợ',\n  'ông',\n  'là',\n  'bà',\n  'martha',\n  'thấy',\n  'là',\n  'đang',\n  'ngồi',\n  'sụp',\n  'xuống',\n  'cái',\n  'đe',\n  'trong',\n  'lò_rèn',\n  'của',\n  'mình',\n  '.'],\n ['theo',\n  'lời',\n  'bà',\n  'ấy',\n  'thì',\n  'ông',\n  'đang',\n  'khóc',\n  'như',\n  'một',\n  'đứa',\n  'trẻ',\n  '.']]"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"tokenized_english = []\nfor row in english:\n    sentence = row[0].lower()\n    # remove \", - characters\n    cleaned = re.sub(r'[\"\\-]', '', sentence)\n    # split by space\n    tokens = cleaned.split()\n    tokenized_english.append(tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:21:58.876283Z","iopub.execute_input":"2025-09-21T08:21:58.876558Z","iopub.status.idle":"2025-09-21T08:21:59.087269Z","shell.execute_reply.started":"2025-09-21T08:21:58.876535Z","shell.execute_reply":"2025-09-21T08:21:59.086424Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"tokenized_english[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:21:59.088122Z","iopub.execute_input":"2025-09-21T08:21:59.088804Z","iopub.status.idle":"2025-09-21T08:21:59.094433Z","shell.execute_reply.started":"2025-09-21T08:21:59.088727Z","shell.execute_reply":"2025-09-21T08:21:59.093698Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"[['the', 'secrets', 'of', 'britain', \"'s\", 'abandoned', 'villages'],\n ['the',\n  'ghosts',\n  'of',\n  'thousands',\n  'of',\n  'longforgotten',\n  'villages',\n  'haunt',\n  'britain',\n  ',',\n  'inhabitations',\n  'suddenly',\n  'deserted',\n  'and',\n  'left',\n  'to',\n  'ruin',\n  '.'],\n ['as',\n  'a',\n  'new',\n  'campaign',\n  'begins',\n  'to',\n  'shed',\n  'further',\n  'light',\n  'on',\n  'these',\n  'forgotten',\n  'histories',\n  ',',\n  'the',\n  'magazine',\n  'asks',\n  'what',\n  'happened',\n  'and',\n  'why',\n  '?'],\n ['albert',\n  'nash',\n  ',',\n  'blacksmith',\n  'for',\n  '44',\n  'years',\n  'in',\n  'the',\n  'village',\n  'of',\n  'imber',\n  ',',\n  'wiltshire',\n  ',',\n  'was',\n  'found',\n  'by',\n  'his',\n  'wife',\n  'martha',\n  'slumped',\n  'over',\n  'the',\n  'anvil',\n  'in',\n  'his',\n  'forge',\n  '.'],\n ['he',\n  'was',\n  ',',\n  'in',\n  'her',\n  'words',\n  ',',\n  'crying',\n  'like',\n  'a',\n  'baby',\n  '.']]"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"from gensim.models import Word2Vec\n\ncorpus = tokenized_vietnamese + tokenized_english   # your two lists above\nmodel = Word2Vec(\n    corpus,\n    vector_size=300,\n    window=5,\n    min_count=1,\n    sg=1,          # skip-gram (better for small data)\n    workers=4\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:21:59.095186Z","iopub.execute_input":"2025-09-21T08:21:59.095433Z","iopub.status.idle":"2025-09-21T08:22:30.707468Z","shell.execute_reply.started":"2025-09-21T08:21:59.095416Z","shell.execute_reply":"2025-09-21T08:22:30.706910Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"model.wv.most_similar('bed', topn=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:22:30.708240Z","iopub.execute_input":"2025-09-21T08:22:30.708449Z","iopub.status.idle":"2025-09-21T08:22:30.739510Z","shell.execute_reply.started":"2025-09-21T08:22:30.708433Z","shell.execute_reply":"2025-09-21T08:22:30.738719Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"[('kitchen', 0.9438347220420837),\n ('bathroom', 0.9420380592346191),\n ('bedroom', 0.9409512877464294),\n ('walk', 0.9293080568313599),\n ('shoes', 0.927649974822998),\n ('coat', 0.9225716590881348),\n ('lights', 0.9216036200523376),\n ('corner', 0.9181979894638062),\n ('room', 0.9161189198493958),\n ('walking', 0.9155673384666443)]"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"word_vectors = model.wv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:22:30.740367Z","iopub.execute_input":"2025-09-21T08:22:30.741074Z","iopub.status.idle":"2025-09-21T08:22:30.748857Z","shell.execute_reply.started":"2025-09-21T08:22:30.741053Z","shell.execute_reply":"2025-09-21T08:22:30.748359Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"import numpy as np\nstoi = {w: i+4 for i, w in enumerate(word_vectors.key_to_index)}\nspecials = ['<pad>', '<sos>', '<eos>', '<unk>']\nfor i,s in enumerate(specials): stoi[s] = i\nitos = {i:s for s,i in stoi.items()}\n\nembedding_dim = 300\nembedding_matrix = np.zeros((len(stoi), embedding_dim))\nfor w, idx in stoi.items():\n    if w in word_vectors:\n        embedding_matrix[idx] = word_vectors[w]\n    else:\n        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:22:30.751254Z","iopub.execute_input":"2025-09-21T08:22:30.751583Z","iopub.status.idle":"2025-09-21T08:22:31.024715Z","shell.execute_reply.started":"2025-09-21T08:22:30.751561Z","shell.execute_reply":"2025-09-21T08:22:31.023922Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"def encode_sentence(tokens, stoi, max_len):\n    ids = [stoi.get(\"<sos>\")]\n    ids += [stoi.get(t, stoi[\"<unk>\"]) for t in tokens]\n    ids.append(stoi.get(\"<eos>\"))\n    ids = ids[:max_len] + [stoi[\"<pad>\"]] * max(0, max_len - len(ids))\n    return ids\n\nmax_len_src = 40\nmax_len_tgt = 40\n\nsrc_ids = [encode_sentence(s, stoi, max_len_src) for s in tokenized_english]\ntgt_ids = [encode_sentence(s, stoi, max_len_tgt) for s in tokenized_vietnamese]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:22:31.025558Z","iopub.execute_input":"2025-09-21T08:22:31.025811Z","iopub.status.idle":"2025-09-21T08:22:32.053759Z","shell.execute_reply.started":"2025-09-21T08:22:31.025789Z","shell.execute_reply":"2025-09-21T08:22:32.053138Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass TranslationDataset(Dataset):\n    def __init__(self, src, tgt):\n        self.src, self.tgt = src, tgt\n    def __len__(self): return len(self.src)\n    def __getitem__(self, i):\n        return torch.tensor(self.src[i]), torch.tensor(self.tgt[i])\n\ntrain_ds = TranslationDataset(src_ids, tgt_ids)\ntrain_dl = DataLoader(train_ds, batch_size=32, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:22:32.054381Z","iopub.execute_input":"2025-09-21T08:22:32.054594Z","iopub.status.idle":"2025-09-21T08:22:32.076597Z","shell.execute_reply.started":"2025-09-21T08:22:32.054578Z","shell.execute_reply":"2025-09-21T08:22:32.075809Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:29:50.128703Z","iopub.execute_input":"2025-09-21T08:29:50.128947Z","iopub.status.idle":"2025-09-21T08:29:50.132820Z","shell.execute_reply.started":"2025-09-21T08:29:50.128931Z","shell.execute_reply":"2025-09-21T08:29:50.132095Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:29:53.255397Z","iopub.execute_input":"2025-09-21T08:29:53.256127Z","iopub.status.idle":"2025-09-21T08:29:53.260835Z","shell.execute_reply.started":"2025-09-21T08:29:53.256104Z","shell.execute_reply":"2025-09-21T08:29:53.260108Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass TranslationTransformer(nn.Module):\n    def __init__(self, vocab_size, embed_dim, nhead=6,\n                 num_layers=4, ff_dim=512, dropout=0.1, max_len=500):\n        super().__init__()\n        self.embedding = nn.Embedding.from_pretrained(\n            torch.tensor(embedding_matrix, dtype=torch.float),\n            freeze=False,\n            padding_idx=stoi[\"<pad>\"]\n        )\n        self.pos_enc = nn.Parameter(torch.zeros(1, max_len, embed_dim))\n\n        self.transformer = nn.Transformer(\n            d_model=embed_dim,\n            nhead=nhead,\n            num_encoder_layers=num_layers,\n            num_decoder_layers=num_layers,\n            dim_feedforward=ff_dim,\n            dropout=dropout,\n            batch_first=True,\n        )\n        self.fc_out = nn.Linear(embed_dim, vocab_size)\n\n    def forward(self, src, tgt):\n        \"\"\"\n        src: (batch, src_len)\n        tgt: (batch, tgt_len)\n        \"\"\"\n        device = src.device\n\n        # --- Embeddings + positional encodings ---\n        src_emb = self.embedding(src) + self.pos_enc[:, :src.size(1), :]\n        tgt_emb = self.embedding(tgt) + self.pos_enc[:, :tgt.size(1), :]\n\n        # --- Masks ---\n        # 1) Look-ahead (causal) mask for the decoder\n        tgt_len = tgt.size(1)\n        tgt_mask = nn.Transformer.generate_square_subsequent_mask(\n            tgt_len, device=device\n        )\n\n        # 2) Padding masks\n        src_pad_mask = (src == stoi[\"<pad>\"])\n        tgt_pad_mask = (tgt == stoi[\"<pad>\"])\n\n        out = self.transformer(\n            src_emb,\n            tgt_emb,\n            tgt_mask=tgt_mask,\n            src_key_padding_mask=src_pad_mask,\n            tgt_key_padding_mask=tgt_pad_mask,\n            memory_key_padding_mask=src_pad_mask,\n        )\n        return self.fc_out(out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T08:48:21.035208Z","iopub.execute_input":"2025-09-21T08:48:21.035670Z","iopub.status.idle":"2025-09-21T08:48:21.043137Z","shell.execute_reply.started":"2025-09-21T08:48:21.035649Z","shell.execute_reply":"2025-09-21T08:48:21.042192Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"translation_model = TranslationTransformer(vocab_size, embed_dim).to(device)\ncriterion = nn.CrossEntropyLoss(ignore_index=stoi[\"<pad>\"])\noptimizer = torch.optim.Adam(translation_model.parameters(), lr=1e-4)\n\nfor epoch in range(20):\n    translation_model.train()\n    for src, tgt in train_dl:\n        src = src.to(device)\n        tgt = tgt.to(device)\n\n        optimizer.zero_grad()\n        output = translation_model(src, tgt[:, :-1])\n        loss = criterion(\n            output.reshape(-1, vocab_size),\n            tgt[:, 1:].reshape(-1)\n        )\n        loss.backward()\n        optimizer.step()\n    print(f\"Epoch {epoch+1}, loss={loss.item():.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T09:01:49.313035Z","iopub.execute_input":"2025-09-21T09:01:49.313867Z","iopub.status.idle":"2025-09-21T09:29:18.136270Z","shell.execute_reply.started":"2025-09-21T09:01:49.313834Z","shell.execute_reply":"2025-09-21T09:29:18.135411Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, loss=5.5053\nEpoch 2, loss=4.8538\nEpoch 3, loss=4.5620\nEpoch 4, loss=3.5409\nEpoch 5, loss=3.8521\nEpoch 6, loss=3.0911\nEpoch 7, loss=2.8989\nEpoch 8, loss=2.6405\nEpoch 9, loss=2.3667\nEpoch 10, loss=1.9655\nEpoch 11, loss=1.9991\nEpoch 12, loss=1.8039\nEpoch 13, loss=1.6820\nEpoch 14, loss=1.3942\nEpoch 15, loss=1.3431\nEpoch 16, loss=1.0628\nEpoch 17, loss=1.2315\nEpoch 18, loss=1.1151\nEpoch 19, loss=0.9351\nEpoch 20, loss=0.8998\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"def translate(sentence_text: str, lang: str = \"en\") -> list[str]:\n    \"\"\"\n    Greedy decoding for a single sentence.\n    \"\"\"\n    translation_model.eval()\n    device = next(translation_model.parameters()).device  # GPU or CPU\n\n    # 1) Tokenize\n    if lang == \"vi\":\n        from underthesea import word_tokenize\n        tokens = word_tokenize(sentence_text.lower())\n    else:\n        tokens = sentence_text.lower().strip().split()\n\n    # 2) Encode source\n    src_ids = torch.tensor(\n        [encode_sentence(tokens, stoi, max_len_src)],\n        dtype=torch.long,\n        device=device\n    )\n\n    # 3) Greedy decoding\n    tgt_tokens = [stoi[\"<sos>\"]]\n    for _ in range(max_len_tgt):\n        tgt_ids = torch.tensor([tgt_tokens], dtype=torch.long, device=device)\n        with torch.no_grad():\n            logits = translation_model(src_ids, tgt_ids)\n        next_id = logits[0, -1].argmax(dim=-1).item()\n        if next_id == stoi[\"<eos>\"]:\n            break\n        tgt_tokens.append(next_id)\n\n    return [itos[i] for i in tgt_tokens[1:]]  # drop <sos>","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T09:54:13.121466Z","iopub.execute_input":"2025-09-21T09:54:13.121745Z","iopub.status.idle":"2025-09-21T09:54:13.127859Z","shell.execute_reply.started":"2025-09-21T09:54:13.121728Z","shell.execute_reply":"2025-09-21T09:54:13.127034Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"print(\" \".join(translate(\"the dog is red\", lang=\"en\")))\nprint(\" \".join(translate(\"con chó màu đỏ\", lang=\"vi\")))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T09:54:15.773623Z","iopub.execute_input":"2025-09-21T09:54:15.773901Z","iopub.status.idle":"2025-09-21T09:54:16.015699Z","shell.execute_reply.started":"2025-09-21T09:54:15.773874Z","shell.execute_reply":"2025-09-21T09:54:16.014816Z"}},"outputs":[{"name":"stdout","text":"chú chó đỏ là màu đỏ\nshin ji\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n  output = torch._nested_tensor_from_mask(\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"x = input(\"Enter your english sentence: \")\nprint(\" \".join(translate(x, lang=\"en\")))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T09:55:47.525780Z","iopub.execute_input":"2025-09-21T09:55:47.526249Z","iopub.status.idle":"2025-09-21T09:56:02.228172Z","shell.execute_reply.started":"2025-09-21T09:55:47.526227Z","shell.execute_reply":"2025-09-21T09:56:02.227541Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your english sentence:  Doctor is the best\n"},{"name":"stdout","text":"bác_sĩ giỏi nhất\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}